/**
 * Frage-f√ºr-Frage Chatbot f√ºr Nachfolge-Beratung
 * 
 * Ein strukturierter Chatbot, der Nutzer schrittweise durch ein Beratungsgespr√§ch f√ºhrt.
 * Nutzt Cloudflare Workers AI f√ºr intelligente, kontextbezogene Antworten auf Deutsch.
 * 
 * @license MIT
 */
import { Env, ChatMessage } from "./types";

// Model ID f√ºr Workers AI
const MODEL_ID = "@cf/mistral/mistral-7b-instruct-v0.1";

// Strukturierter Fragenkatalog f√ºr die Nachfolge-Beratung
const QUESTIONS = [
  "Herzlich willkommen! Ich bin Ihr digitaler Nachfolge-Berater. Um Sie besser zu unterst√ºtzen, erz√§hlen Sie mir bitte etwas √ºber Ihr Unternehmen. Was bewegt Sie aktuell bez√ºglich Ihrer Nachfolge? Was ist Ihr gr√∂√ütes Ziel dabei?",
  "Sch√∂n, Sie kennenzulernen! Welche Art von Unternehmen f√ºhren Sie?",
  "Wie viele Mitarbeiter besch√§ftigt Ihr Unternehmen aktuell?",
  "In welcher Branche ist Ihr Unternehmen t√§tig?",
  "Seit wann besteht Ihr Unternehmen?",
  "Was ist Ihr Hauptgrund f√ºr die √úberlegung zur Nachfolgeplanung?",
  "Haben Sie bereits potenzielle Nachfolger im Blick (Familie, Mitarbeiter, externe K√§ufer)?",
  "Welcher Zeitrahmen schwebt Ihnen f√ºr die √úbergabe vor?",
  "Was sind Ihre wichtigsten Ziele f√ºr die Nachfolge (finanzielle Absicherung, Fortbestand des Unternehmens, etc.)?",
  "Vielen Dank f√ºr Ihre Antworten! M√∂chten Sie noch etwas hinzuf√ºgen oder haben Sie Fragen?",
];

// System-Prompt f√ºr den AI-Assistenten
const SYSTEM_PROMPT = `Du bist ein erfahrener Berater f√ºr Unternehmensnachfolge mit √ºber 25 Jahren Praxiserfahrung.
Du sprichst mit der Ruhe und Klarheit eines Experten um die 50, der bereits viele √úbergaben begleitet hat.
Dein Ton ist warm, vertrauensw√ºrdig und pers√∂nlich ‚Äì du stellst nicht nur Fragen, sondern ordnest kurz ein und nimmst die Sorgen und Hoffnungen deines Gegen√ºbers wahr.

Wichtige Regeln:
1. Antworte IMMER auf Deutsch.
2. Sei freundlich, vertrauensvoll und authentisch.
3. Hebe die Komplexit√§t und Bedeutung der Nachfolge bei Bedarf kurz hervor (Lebenswerk, Verantwortung f√ºr Mitarbeitende, Familie, Zukunftssicherung).
4. Gehe auf die Antworten des Nutzers ein, spiegle Kernpunkte und leite zur n√§chsten Frage √ºber.
5. Halte Antworten pr√§gnant (2‚Äì4 S√§tze) und substanziell.
6. Nutze gelegentlich anschauliche, kurze Praxisbeispiele ohne abzuschweifen.
7. WICHTIG: Stelle dich NICHT erneut vor, nachdem die Willkommensnachricht bereits gesendet wurde. Verzichte auf Aussagen wie "Ich begleite Unternehmer seit..." oder √§hnliche Selbstvorstellungen in Folgeantworten. Bleibe direkt und kontextbezogen.`;

/**
 * Haupthandler f√ºr Chat-Anfragen
 */
async function handleChatRequest(
  request: Request,
  env: Env
): Promise<Response> {
  try {
    const { history = [], userMessage }: { history: ChatMessage[]; userMessage: string } =
      await request.json();

    console.log("üì• Eingehende Anfrage:", { historyLength: history.length, userMessage });

    const questionIndex = Math.floor(history.length / 2);
    const currentQuestion = QUESTIONS[questionIndex];

    console.log("üîç Frage-Index:", questionIndex, "von", QUESTIONS.length);

    // Falls alle Fragen beantwortet wurden, sende eine Abschlussnachricht
    if (questionIndex >= QUESTIONS.length) {
      return new Response(
        JSON.stringify({ response: "Vielen Dank f√ºr das Gespr√§ch! Ich werde mich bald bei Ihnen melden." }),
        { headers: { "Content-Type": "application/json", "Access-Control-Allow-Origin": "*" } }
      );
    }

    const aiMessages = [
      { role: "system", content: SYSTEM_PROMPT },
      ...history.map((msg) => ({
        role: msg.sender === "bot" ? "assistant" : "user",
        content: msg.content,
      })),
      { role: "user", content: userMessage },
      {
        role: "system",
        content: `Die n√§chste Frage lautet: "${currentQuestion}". Gehe kurz und pers√∂nlich auf die Antwort des Nutzers ein und stelle dann die n√§chste Frage. Vermeide jede Form von Selbstvorstellung oder Wiederholung deiner Erfahrung.`,
      },
    ];

    console.log("ü§ñ AI Messages:", aiMessages);

    const response = await env.AI.run(MODEL_ID, {
      messages: aiMessages,
      stream: true,
    });

    return new Response(response, {
      headers: {
        "Content-Type": "text/event-stream",
        "Access-Control-Allow-Origin": "*",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
      },
    });
  } catch (error) {
    console.error("Chat request error:", error);
    return new Response(
      JSON.stringify({ error: "Chat request failed", details: String(error) }),
      {
        status: 500,
        headers: {
          "Content-Type": "application/json",
          "Access-Control-Allow-Origin": "*",
        },
      }
    );
  }
}

/**
 * Worker Entry Point
 */
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url);

    // Handle CORS preflight requests
    if (request.method === "OPTIONS") {
      return new Response(null, {
        headers: {
          "Access-Control-Allow-Origin": "*",
          "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
        },
      });
    }

    // API Endpoint: /api/chat
    if (url.pathname === "/api/chat" && request.method === "POST") {
      return handleChatRequest(request, env);
    }

    // Serve static files from /public
    const assetResponse = await env.ASSETS.fetch(request);
    return assetResponse;
  },
};
